Some important codes...

define hyper-parameters
num_hidden = 100

num_step = 3001

num_features = 192

num_class = 99

learning_rate = 0.1

Placeholders, weights and biases
x = tf.placeholder(tf.float32, [None, num_features])

W_1 = tf.Variable(tf.zeros([num_features, num_hidden]))

b_1 = tf.Variable(tf.zeros([num_hidden]))

W_2 = tf.Variable(tf.zeros([num_hidden, num_class]))

b_2 = tf.Variable(tf.zeros([num_class]))

hidden = tf.nn.softmax(tf.matmul(x, W_1) + b_1)

hidden = tf.nn.softmax(tf.matmul(hidden,W_2) + b_2)

the true tag goes here
y_ = tf.placeholder(tf.float32, [None, num_class])

define cross entropy as cost function
cross_entropy = -tf.reduce_sum(y_*tf.log(hidden))

minimize cross_entropy using the Adam algorithm with a learning rate of 0.0.
train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)

launch the model in a Session, run the initialized operation
init = tf.initialize_all_variables()

sess = tf.Session()

sess.run(init)

evaluation
correct_prediction = tf.equal(tf.argmax(hidden,1), tf.argmax(y_,1))

accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

define inputs
test_xs, test_ys = load_training('data/tftest.csv')

batch_xs, batch_ys = load_training('data/ctrain.csv')

header,id,dev = load_test('data/test.csv','data/sample_submission.csv')

train_step feeding in the batches data to replace the placeholders
for i in range(num_step):

_,loss = sess.run([train_step,cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})
if i % 100 == 0:
    acc = sess.run(accuracy, feed_dict={x: test_xs, y_: test_ys})
    print (i, loss, acc)

if i == (num_step-1) :
    submission = open('data/sub.csv', 'w')
    submission.write(header)
    results = sess.run(hidden, feed_dict= {x:dev})
    for index,item in enumerate(results):
        submission.write(id[index]+',')
        strings = [str(x) for x in item]
        submission.write(','.join(strings)+'\n')


    print ('Finished!')

    submission.close()
